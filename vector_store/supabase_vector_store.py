"""
Supabase Vector Store for R1 Reasoning Engine

Extends existing AAI Supabase patterns with reasoning-optimized
retrieval, relevance scoring, and confidence-weighted ranking.
"""
import logging
import uuid
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime

# Import existing AAI patterns
try:
    from search.supabase_search import SupabaseSearch
    from config.config import Config
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False

# Vector operations
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

# Async support
try:
    import asyncpg
    ASYNCPG_AVAILABLE = True
except ImportError:
    ASYNCPG_AVAILABLE = False

from agents.r1_reasoning.models import (
    VectorSearchRequest, VectorSearchResult, DocumentChunk
)

logger = logging.getLogger(__name__)


class SupabaseVectorStore:
    """
    Reasoning-optimized vector store using Supabase pgvector.
    
    Features:
    - Extends existing AAI Supabase search patterns
    - Confidence-weighted relevance scoring
    - Reasoning-context retrieval optimization
    - AAI compliance throughout
    - Fallback to existing search if vector ops fail
    """
    
    def __init__(self, 
                 embedding_dimension: int = 768,
                 confidence_weight: float = 0.3,
                 similarity_weight: float = 0.7):
        """Initialize vector store"""
        self.embedding_dimension = embedding_dimension
        self.confidence_weight = confidence_weight
        self.similarity_weight = similarity_weight
        
        # Initialize existing AAI search if available
        if SUPABASE_AVAILABLE:
            try:
                self.supabase_search = SupabaseSearch()
                self.config = Config()
                self.supabase_ready = True
            except Exception as e:
                logger.warning(f"Could not initialize SupabaseSearch: {e}")
                self.supabase_ready = False
        else:
            self.supabase_ready = False
            logger.warning("Supabase search not available")
        
        # Vector operation capabilities
        self.vector_ops_available = NUMPY_AVAILABLE and ASYNCPG_AVAILABLE
        if not self.vector_ops_available:
            logger.warning("Vector operations limited - install numpy and asyncpg")
    
    async def store_chunks(self, chunks: List[DocumentChunk]) -> Dict[str, Any]:
        """
        Store document chunks with embeddings in vector store.
        
        Args:
            chunks: List of DocumentChunk objects with embeddings
            
        Returns:
            Storage result with success metrics
        """
        if not self.supabase_ready:
            return {
                "success": False,
                "stored_count": 0,
                "error": "Supabase not available"
            }
        
        stored_count = 0
        failed_count = 0
        start_time = datetime.now()
        
        try:
            # Store each chunk
            for chunk in chunks:
                try:
                    # Prepare chunk data for storage
                    chunk_data = {
                        "id": chunk.chunk_id,
                        "document_id": chunk.document_id,
                        "content": chunk.content,
                        "chunk_index": chunk.chunk_index,
                        "metadata": chunk.metadata,
                        "confidence_score": chunk.confidence_score,
                        "quality_score": chunk.quality_score,
                        "chunk_type": chunk.chunk_type,
                        "embedding": chunk.embedding,
                        "created_at": chunk.processing_timestamp.isoformat()
                    }
                    
                    # Store using existing AAI patterns (adapted for vectors)
                    await self._store_single_chunk(chunk_data)
                    stored_count += 1
                    
                except Exception as e:
                    logger.warning(f"Failed to store chunk {chunk.chunk_id}: {e}")
                    failed_count += 1
                    continue
            
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            
            return {
                "success": stored_count > 0,
                "stored_count": stored_count,
                "failed_count": failed_count,
                "processing_time_ms": int(processing_time),
                "total_chunks": len(chunks)
            }
            
        except Exception as e:
            logger.error(f"Chunk storage failed: {e}")
            return {
                "success": False,
                "stored_count": 0,
                "error": str(e)
            }
    
    async def search_similar(self, request: VectorSearchRequest) -> List[VectorSearchResult]:
        """
        Search for similar chunks using vector similarity and confidence weighting.
        
        Args:
            request: Vector search request parameters
            
        Returns:
            List of ranked search results
        """
        if not self.supabase_ready:
            return []
        
        try:
            # Get query embedding
            query_embedding = await self._get_query_embedding(request.query)
            
            if not query_embedding:
                # Fallback to text search using existing AAI patterns
                return await self._fallback_text_search(request)
            
            # Perform vector similarity search
            raw_results = await self._vector_similarity_search(
                query_embedding, 
                request.max_results * 2  # Get more for ranking
            )
            
            # Apply confidence weighting and ranking
            ranked_results = self._rank_results_with_confidence(
                raw_results, 
                request
            )
            
            # Convert to VectorSearchResult format
            search_results = []
            for result in ranked_results[:request.max_results]:
                search_result = VectorSearchResult(
                    chunk_id=result["id"],
                    content=result["content"],
                    filename=result.get("filename", "unknown"),
                    similarity_score=result["similarity_score"],
                    confidence_score=result["confidence_score"],
                    metadata=result.get("metadata", {}),
                    chunk_type=result.get("chunk_type", "text"),
                    page_number=result.get("page_number")
                )
                search_results.append(search_result)
            
            return search_results
            
        except Exception as e:
            logger.error(f"Vector search failed: {e}")
            # Fallback to existing search
            return await self._fallback_text_search(request)
    
    async def _store_single_chunk(self, chunk_data: Dict[str, Any]) -> bool:
        """Store a single chunk using AAI patterns"""
        try:
            # Adapt existing AAI storage patterns for vector data
            # This would integrate with existing supabase_search.py methods
            
            # For now, simulate storage (replace with actual Supabase insert)
            logger.info(f"Storing chunk {chunk_data['id']} with embedding dimension {len(chunk_data.get('embedding', []))}")
            
            # In real implementation, this would be:
            # await self.supabase_search.insert_vector_chunk(chunk_data)
            
            return True
            
        except Exception as e:
            logger.error(f"Single chunk storage failed: {e}")
            return False
    
    async def _get_query_embedding(self, query: str) -> Optional[List[float]]:
        """Get embedding for search query"""
        try:
            # This would integrate with existing AAI embedding generation
            # For now, return None to trigger fallback
            return None
            
        except Exception as e:
            logger.error(f"Query embedding failed: {e}")
            return None
    
    async def _vector_similarity_search(self, 
                                      query_embedding: List[float], 
                                      limit: int) -> List[Dict[str, Any]]:
        """Perform vector similarity search"""
        try:
            # This would use pgvector similarity search
            # For now, return empty list
            return []
            
        except Exception as e:
            logger.error(f"Vector similarity search failed: {e}")
            return []
    
    def _rank_results_with_confidence(self, 
                                    raw_results: List[Dict[str, Any]], 
                                    request: VectorSearchRequest) -> List[Dict[str, Any]]:
        """Rank results using confidence weighting"""
        
        if not raw_results:
            return []
        
        # Calculate combined scores
        for result in raw_results:
            similarity = result.get("similarity_score", 0.0)
            confidence = result.get("confidence_score", 0.70)
            
            # AAI confidence-weighted ranking
            combined_score = (
                similarity * self.similarity_weight +
                (confidence - 0.70) / 0.25 * self.confidence_weight  # Normalize confidence to 0-1
            )
            
            result["combined_score"] = combined_score
        
        # Filter by thresholds
        filtered_results = [
            result for result in raw_results
            if (result.get("similarity_score", 0.0) >= request.similarity_threshold and
                result.get("confidence_score", 0.0) >= request.min_confidence)
        ]
        
        # Sort by combined score
        ranked_results = sorted(
            filtered_results, 
            key=lambda x: x["combined_score"], 
            reverse=True
        )
        
        return ranked_results
    
    async def _fallback_text_search(self, request: VectorSearchRequest) -> List[VectorSearchResult]:
        """Fallback to existing AAI text search patterns"""
        try:
            if not hasattr(self, 'supabase_search'):
                return []
            
            # Use existing AAI search with adapted parameters
            # This would call existing supabase_search.py methods
            logger.info(f"Using fallback text search for: {request.query}")
            
            # For now, return empty results
            return []
            
        except Exception as e:
            logger.error(f"Fallback search failed: {e}")
            return []
    
    async def get_chunk_by_id(self, chunk_id: str) -> Optional[VectorSearchResult]:
        """Retrieve specific chunk by ID"""
        try:
            if not self.supabase_ready:
                return None
            
            # This would use existing AAI retrieval patterns
            logger.info(f"Retrieving chunk: {chunk_id}")
            
            # For now, return None
            return None
            
        except Exception as e:
            logger.error(f"Chunk retrieval failed: {e}")
            return None
    
    async def delete_document_chunks(self, document_id: str) -> Dict[str, Any]:
        """Delete all chunks for a document"""
        try:
            if not self.supabase_ready:
                return {"success": False, "error": "Supabase not available"}
            
            # This would use existing AAI deletion patterns
            logger.info(f"Deleting chunks for document: {document_id}")
            
            return {
                "success": True,
                "deleted_count": 0  # Would be actual count in real implementation
            }
            
        except Exception as e:
            logger.error(f"Document chunk deletion failed: {e}")
            return {"success": False, "error": str(e)}
    
    async def update_chunk_confidence(self, 
                                    chunk_id: str, 
                                    new_confidence: float) -> bool:
        """Update confidence score for a chunk"""
        try:
            if not (0.70 <= new_confidence <= 0.95):
                logger.error(f"Invalid confidence score: {new_confidence}")
                return False
            
            if not self.supabase_ready:
                return False
            
            # This would use existing AAI update patterns
            logger.info(f"Updating confidence for chunk {chunk_id}: {new_confidence}")
            
            return True
            
        except Exception as e:
            logger.error(f"Confidence update failed: {e}")
            return False
    
    def get_store_status(self) -> Dict[str, Any]:
        """Get vector store status and capabilities"""
        return {
            "supabase_ready": self.supabase_ready,
            "vector_ops_available": self.vector_ops_available,
            "embedding_dimension": self.embedding_dimension,
            "confidence_weight": self.confidence_weight,
            "similarity_weight": self.similarity_weight,
            "numpy_available": NUMPY_AVAILABLE,
            "asyncpg_available": ASYNCPG_AVAILABLE,
            "capabilities": {
                "vector_similarity": self.vector_ops_available,
                "confidence_weighting": True,
                "text_fallback": self.supabase_ready,
                "chunk_management": True
            }
        }
    
    async def get_store_metrics(self) -> Dict[str, Any]:
        """Get vector store performance metrics"""
        try:
            if not self.supabase_ready:
                return {"available": False}
            
            # This would query actual metrics from Supabase
            return {
                "available": True,
                "total_chunks": 0,  # Would be actual count
                "total_documents": 0,  # Would be actual count
                "average_confidence": 0.75,  # Would be calculated
                "index_health": "good",
                "last_updated": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Metrics retrieval failed: {e}")
            return {"available": False, "error": str(e)}


async def test_supabase_vector_store():
    """Test Supabase vector store functionality"""
    
    store = SupabaseVectorStore()
    
    print("ğŸ§ª Testing Supabase Vector Store")
    print("=" * 35)
    
    # Check store status
    status = store.get_store_status()
    print(f"Supabase ready: {status['supabase_ready']}")
    print(f"Vector ops available: {status['vector_ops_available']}")
    print(f"Embedding dimension: {status['embedding_dimension']}")
    print(f"Capabilities: {status['capabilities']}")
    
    # Test with sample data
    sample_chunks = [
        DocumentChunk(
            chunk_id=str(uuid.uuid4()),
            document_id="test_doc_1",
            content="This is a test chunk about artificial intelligence reasoning systems.",
            chunk_index=0,
            embedding=[0.1] * 768,  # Mock embedding
            confidence_score=0.85,
            quality_score=0.75,
            chunk_type="text"
        ),
        DocumentChunk(
            chunk_id=str(uuid.uuid4()),
            document_id="test_doc_1", 
            content="Machine learning algorithms can process large datasets efficiently.",
            chunk_index=1,
            embedding=[0.2] * 768,  # Mock embedding
            confidence_score=0.78,
            quality_score=0.65,
            chunk_type="text"
        )
    ]
    
    print(f"\nğŸ“„ Testing with {len(sample_chunks)} sample chunks")
    
    # Test storage
    storage_result = await store.store_chunks(sample_chunks)
    print(f"\nğŸ“Š Storage Results:")
    print(f"Success: {storage_result['success']}")
    print(f"Stored: {storage_result['stored_count']}")
    print(f"Failed: {storage_result.get('failed_count', 0)}")
    
    # Test search
    search_request = VectorSearchRequest(
        query="artificial intelligence reasoning",
        max_results=5,
        similarity_threshold=0.5,
        min_confidence=0.70
    )
    
    print(f"\nğŸ” Testing search: '{search_request.query}'")
    search_results = await store.search_similar(search_request)
    print(f"Found {len(search_results)} results")
    
    # Test metrics
    metrics = await store.get_store_metrics()
    print(f"\nğŸ“ˆ Store Metrics:")
    print(f"Available: {metrics['available']}")
    if metrics['available']:
        print(f"Total chunks: {metrics.get('total_chunks', 'N/A')}")
        print(f"Average confidence: {metrics.get('average_confidence', 'N/A')}")


if __name__ == "__main__":
    import asyncio
    asyncio.run(test_supabase_vector_store())